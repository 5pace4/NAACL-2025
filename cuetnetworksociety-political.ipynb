{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom transformers import (AutoTokenizer, AutoModelForSequenceClassification, \n                          Trainer, TrainingArguments)\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfrom datasets import Dataset\nimport time\n!pip install unidecode\nfrom unidecode import unidecode\nimport re","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/ps-dataset/PS_train.csv') \nval_data = pd.read_csv('/kaggle/input/ps-dataset/PS_dev.csv')\ntest_data = pd.read_csv('/kaggle/input/ps-dataset/PS_test_without_lables.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Handle Missing Valuse","metadata":{}},{"cell_type":"code","source":"train_data.dropna(inplace=True)\nval_data.dropna(inplace=True)\ntest_data.dropna(inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocess Dataset","metadata":{}},{"cell_type":"code","source":"\ndef preprocess_text(text):\n    text = unidecode(text)  # Remove accents\n    text = text.lower()  # Lowercase\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n    text = re.sub(r'\\d+', '', text)  # Remove digits\n    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n    return text","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data['content'] = train_data['content'].apply(preprocess_text)\nval_data['content'] = val_data['content'].apply(preprocess_text)\ntest_data['content'] = test_data['content'].apply(preprocess_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Encode labels to integers\nlabel_encoder = LabelEncoder()\ntrain_data['labels'] = label_encoder.fit_transform(train_data['labels'])\nval_data['labels'] = label_encoder.transform(val_data['labels'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dataset Class\nclass TamilDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train and Evaluate the Model","metadata":{}},{"cell_type":"code","source":"# Train and Evaluate Model\ndef train_and_evaluate(model_name):\n    print(f\"Training {model_name}...\")\n    start = time.time()\n\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    \n    train_encodings = tokenizer(list(train_data['content']), padding=True, truncation=True, max_length=256)\n    val_encodings = tokenizer(list(val_data['content']), padding=True, truncation=True, max_length=256)\n\n    \n    train_dataset = TamilDataset(train_encodings, train_data['labels'].tolist())\n    val_dataset = TamilDataset(val_encodings, val_data['labels'].tolist())\n    \n    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(set(train_data['labels'])))\n    model.to(device)\n    \n    # Remove max_length from TrainingArguments\n    training_args = TrainingArguments(\n    output_dir=f\"./results/{model_name}\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    per_device_train_batch_size=8, \n    per_device_eval_batch_size=8,  \n    num_train_epochs=17,\n    logging_dir=f\"./logs/{model_name}\",\n    logging_steps=200,\n    fp16=True,  # Ensure fp16 is enabled\n    report_to=\"none\",\n    learning_rate=5e-6,\n    warmup_steps=500,\n    weight_decay=0.02,\n    save_total_limit=1,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    gradient_accumulation_steps=8,\n    seed=42,\n    lr_scheduler_type=\"cosine\",\n    disable_tqdm=False,\n)\n trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n        tokenizer=tokenizer\n    )\n    \n    trainer.train()\n    predictions = trainer.predict(val_dataset).predictions.argmax(axis=1)\n    accuracy = accuracy_score(val_data['labels'], predictions)\n    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n    print(classification_report(val_data['labels'], predictions))\n    print(\"Training Time:\", time.time() - start)\n\n    return model, tokenizer, trainer","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict on Test Set\ndef predict_on_test(model, tokenizer, trainer):\n    print(\"Predicting on Test Data...\")\n    \n    test_encodings = tokenizer(list(test_data['content']), padding=True, truncation=True, max_length=512)\n    test_dataset = TamilDataset(test_encodings, [0]*len(test_data))\n    \n    predictions = trainer.predict(test_dataset).predictions.argmax(axis=1)\n    \n    predicted_labels = label_encoder.inverse_transform(predictions)\n    \n    test_data['predicted_labels'] = predicted_labels\n    test_data[['Id', 'predicted_labels']].to_csv('/kaggle/working/mbert_predictions.csv', index=False)\n    print(\"Predictions saved to test_predictions.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_name = \"bert-base-multilingual-cased\"\n\nmodel, tokenizer, trainer = train_and_evaluate(model_name)\npredict_on_test(model, tokenizer, trainer)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}